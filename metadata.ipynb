{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "import folium\n",
    "import functools\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load sample data\n",
    "To start out, you will need a CSV file with one row for each sample. It must have columns titled `latitude`, `longitude`, and `sample_id`. We will use the coordinates to get more data about each sample location.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (278, 3)\n",
      "  sample_id   longitude   latitude\n",
      "0   K0024A2 -118.567312  34.083974\n",
      "1   K0024B2 -118.570642  34.084767\n",
      "2   K0024C1 -118.551882  34.055978\n",
      "3   K0026A1 -117.229718  32.853963\n",
      "4   K0026B1 -117.232750  32.849619\n"
     ]
    }
   ],
   "source": [
    "csv_path = 'sample_input.csv'\n",
    "\n",
    "# Read the relevant columns from the CSV into a dataframe\n",
    "samples = pd.read_csv(csv_path, usecols=['sample_id', 'longitude', 'latitude'])\n",
    "\n",
    "# Display the shape of the data we read in and its first few rows\n",
    "print(\"Data shape:\", samples.shape)\n",
    "print(samples.head())\n",
    "\n",
    "# Define a Feature for each 100-meter-radius sample area\n",
    "sample_areas = []\n",
    "for sample in samples.itertuples():\n",
    "    # Store the important data as properties of the feature\n",
    "    sample_areas.append(\n",
    "        ee.Feature(ee.Geometry.Point(sample.longitude, sample.latitude).buffer(100))\n",
    "        .set('name', sample.sample_id)\n",
    "        .set('longitude', sample.longitude)\n",
    "        .set('latitude', sample.latitude))\n",
    "\n",
    "# Define a FeatureCollection containing all the sample areas\n",
    "sample_areas = ee.FeatureCollection(sample_areas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define dataset classes\n",
    "GIS datasets can be in either vector or raster format. In Google Earth Engine, raster data is represented by an `Image` or `ImageCollection` and vector data by a `FeatureCollection`. You can find datasets by searching in the [Earth Engine data catalog](https://developers.google.com/earth-engine/datasets). It's also possible to instantiate an Earth Engine object from data that you have locally if it's not available through the API.\n",
    "\n",
    "To conceptualize the data it will be helpful to wrap these Earth Engine objects in our own classes. This way we can store information we need to use the dataset alongside it: the band or property to use and how to process and display the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raster datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RasterDataset:\n",
    "    \n",
    "    def __init__(self, snippet, band, name=None, categorical=False, map_params={}):\n",
    "        \"\"\"\n",
    "        Represent a Google Earth Engine raster dataset and the information we need to use it.\n",
    "        \n",
    "        snippet: The ee.Image or ee.ImageCollection object representing the desired dataset. \n",
    "            This is the snippet of code provided on the dataset's page in the Earth Engine catalog.\n",
    "            e.g.: ee.Image('path') or ee.ImageCollection('path')\n",
    "        band: The identifier of the desired image band e.g. 'bio01'\n",
    "        name: The column name to display for the data gathered from this dataset\n",
    "        categorical: Set to True if the data is not continuous. If True, takes the mode of pixels\n",
    "            in the sample area rather than the median.\n",
    "        map_params: Settings for how to display the data e.g. palette, min, max. \n",
    "            See param options: https://developers.google.com/earth-engine/api_docs#ee.data.getmapid\n",
    "        \"\"\"\n",
    "        \n",
    "        # self.name exists to be a common property between RasterDatasets and VectorDatasets\n",
    "        self.name = name or band  # If a different name is not set, use the band name\n",
    "        self.categorical = categorical\n",
    "        self.map_params = map_params    \n",
    "        \n",
    "        # Select just the one band of interest from the image and rename it to self.name\n",
    "        if isinstance(snippet, ee.ImageCollection):  \n",
    "            # If it's an image collection, mosaic it into one image\n",
    "            self.data = snippet.select([band], [self.name]).mosaic()\n",
    "        else:\n",
    "            self.data = snippet.select([band], [self.name])\n",
    "        \n",
    "        self.band = self.name  \n",
    "        \n",
    "    def get_sample_area_data(self, sample_area: ee.Feature) -> ee.Feature:\n",
    "        \"\"\"\n",
    "        Add a new property to the input feature storing the value of self.data in the feature area\n",
    "        \n",
    "        param sample_area: ee.Feature with the geometry to sample over\n",
    "        returns: input feature with a new property in the form \n",
    "            {self.band: mode (categorical) or median (continuous) of self.data \n",
    "                        over the feature geometry}\n",
    "        \"\"\"\n",
    "        \n",
    "        # Get the average distance from each point in the sample area to the data image\n",
    "        distance = self.distance(sample_area.geometry())\n",
    "        \n",
    "        geometry = ee.Algorithms.If(\n",
    "            distance,  # If the distance is not None,\n",
    "            ee.Algorithms.If(\n",
    "                distance.eq(0),  # If the distance is 0, the data covers the sample area\n",
    "                sample_area.geometry(),\n",
    "                sample_area.geometry().buffer(distance), # Otherwise, we need to buffer it\n",
    "            ),\n",
    "            # If the distance is None, the sample area is farther away from the data than the\n",
    "            # range being searched by the distance kernel.\n",
    "            # Continue with the sample area geometry, the reducer will return None.\n",
    "            sample_area.geometry()\n",
    "        )\n",
    "        result = ee.Algorithms.If(\n",
    "            self.categorical,  # If the data type is categorical,\n",
    "            self.mode(geometry),  # Get the most common category in the sample area\n",
    "            self.median(geometry)  # Otherwise it's continuous, so get the median\n",
    "        )\n",
    "    \n",
    "        return sample_area.set(self.band, result)\n",
    "    \n",
    "    def distance(self, geometry: ee.Geometry) -> ee.Number:\n",
    "        \"\"\"\n",
    "        Return the average distance from each point in the input geometry to the self.data image\n",
    "        \n",
    "        - This should be 0 in most cases, meaning the data covers the sample area.\n",
    "        - If the sample area is within the search radius from the self.data image \n",
    "            (here set to 1000m), the distance will be returned.\n",
    "        - If the sample area is outside the search radius, None is returned.\n",
    "        \n",
    "        This is intended to account for edges of datasets not lining up exactly with the \n",
    "        coastline, leaving some coastal sample sites just outside the self.data image.\n",
    "        \n",
    "        param geometry: ee.Geometry of the sample area of interest\n",
    "        returns: ee.Number (0 or distance) or None\n",
    "        \"\"\"\n",
    "        # Make an image representing the distance from any given point to the self.data image\n",
    "        # This will be 0 everywhere that the self.data image covers\n",
    "        distance_image = self.data.distance(\n",
    "            ee.Kernel.euclidean(1000, 'meters'),\n",
    "            False  # Do not exclude masked pixels\n",
    "        ).select([self.band], ['distance'])  # Rename the band to 'distance'\n",
    "        \n",
    "        # Get the average distance from each point in the sample area to the nearest pixel of data\n",
    "        distance = ee.Number(distance_image.reduceRegion(\n",
    "            reducer=ee.Reducer.mean(),\n",
    "            geometry=geometry,\n",
    "            scale=100,\n",
    "            maxPixels=1e9\n",
    "        ).get('distance'))\n",
    "        \n",
    "        return distance\n",
    "    \n",
    "    def mode(self, geometry: ee.Geometry) -> ee.Number:\n",
    "        \"\"\"\n",
    "        Reduce the dataset over the sample area to get the most common value in that area.\n",
    "        \n",
    "        param geometry: ee.Geometry of the sample area of interest\n",
    "        returns: mode of pixels within the geometry as an ee.Number\n",
    "        \"\"\"\n",
    "        mode = self.data.reduceRegion(\n",
    "            reducer=ee.Reducer.mode(),\n",
    "            geometry=geometry,\n",
    "            scale=100,\n",
    "            maxPixels=1e9\n",
    "        ).get(self.band)\n",
    "        return mode\n",
    "    \n",
    "    def median(self, geometry: ee.Geometry) -> ee.Number:\n",
    "        \"\"\"\n",
    "        Reduce the dataset over the sample area to get the median value in that area\n",
    "        \n",
    "        param geometry: ee.Geometry of the sample area of interest\n",
    "        returns: median of pixels within the geometry as an ee.Number\n",
    "        \"\"\"\n",
    "        median = self.data.reduceRegion(\n",
    "            reducer=ee.Reducer.median(),\n",
    "            geometry=geometry,\n",
    "            scale=100,\n",
    "            maxPixels=1e9\n",
    "        ).get(self.band)\n",
    "        return median\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Vector datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class VectorDataset:\n",
    "    \n",
    "    def __init__(self, snippet, property: str, name=None, map_params={}):\n",
    "        \"\"\"\n",
    "        Represent a Google Earth Engine raster dataset and the information we need to use it.\n",
    "        \n",
    "        snippet: The ee.FeatureCollection object representing the dataset.\n",
    "            This is the 'Earth Engine snippet' displayed on the dataset's page in the Earth \n",
    "            Engine catalog. e.g.: ee.FeatureCollection('EPA/Ecoregions/2013/L3')\n",
    "        property: The key of the desired feature property\n",
    "        name: The column name to display for the data gathered from this dataset.\n",
    "        map_params: Settings for how to display the data e.g. palette, min, max\n",
    "        \"\"\"\n",
    "        self.data = snippet\n",
    "        self.property = property\n",
    "        self.name = name or property\n",
    "        self.map_params = map_params\n",
    "        \n",
    "    # Note: This function is an argument to map(). Arguments to map() cannot print anything\n",
    "    # or call getInfo(). Doing so results in an EEException: ValueNode empty\n",
    "    # source: https://gis.stackexchange.com/questions/345598/mapping-simp>le-function-to-print-date-and-time-stamp-on-google-earth-engine-pyth\n",
    "    def get_sample_area_data(self, sample_area: ee.Feature) -> str:\n",
    "        \"\"\"\n",
    "        Return the value from the dataset to assign to the sample area.\n",
    "        \"\"\"\n",
    "        # Get a FeatureCollection storing the overlaps between the sample area and the dataset\n",
    "        overlaps = self.data.filterBounds(sample_area.geometry()).map(\n",
    "            lambda feature: feature.intersection(sample_area.geometry())\n",
    "        )\n",
    "\n",
    "        result = ee.Algorithms.If(\n",
    "            # If there is exactly 1 overlapping dataset feature, return its value\n",
    "            overlaps.size().eq(1),\n",
    "            sample_area.set(self.name, overlaps.first().get(self.property)),\n",
    "\n",
    "            ee.Algorithms.If(\n",
    "                # If there are 0 overlapping dataset features, return the value of the closest one\n",
    "                overlaps.size().eq(0),\n",
    "                sample_area.set(self.name, \n",
    "                                self.get_nearest_feature(sample_area).get(self.property)),\n",
    "\n",
    "                # Otherwise, there must be >1 features overlapping the sample area\n",
    "                # Return the value of the one with the largest overlap\n",
    "                sample_area.set(self.name, \n",
    "                                self.get_predominant_feature(overlaps).get(self.property))\n",
    "            )\n",
    "        )\n",
    "\n",
    "        return result\n",
    "\n",
    "    def get_nearest_feature(self, sample_area: ee.Feature) -> str:\n",
    "        \"\"\"\n",
    "        To be used when the sample area doesn't overlap the dataset at all.\n",
    "        \n",
    "        Get the dataset feature that is nearest to the sample area, and\n",
    "        return the value of its dataset.property.\n",
    "        \n",
    "        param sample_area: ee.Feature representing the sample area of interest\n",
    "        \"\"\"\n",
    "\n",
    "        # Define a filter to get all dataset features within 10000 meters of the sample area\n",
    "        spatialFilter = ee.Filter.withinDistance(\n",
    "            distance=10000,\n",
    "            leftField='.geo',\n",
    "            rightField='.geo',\n",
    "            maxError=10\n",
    "        )\n",
    "        # Define a join that will return only the 'best' (nearest) match\n",
    "        saveBestJoin = ee.Join.saveBest(\n",
    "          matchKey='closestFeature',\n",
    "          measureKey='distance'\n",
    "        )\n",
    "        # Apply the join, using the distance filter to define match quality\n",
    "        # Get the only feature in the resulting FeatureCollection\n",
    "        result = ee.Feature(saveBestJoin.apply(\n",
    "            ee.FeatureCollection(sample_area),\n",
    "            self.data,\n",
    "            spatialFilter\n",
    "        ).first())\n",
    "\n",
    "        # Return the closest dataset feature\n",
    "        return ee.Feature(result.get('closestFeature'))\n",
    "    \n",
    "    def get_predominant_feature(self, overlaps: ee.FeatureCollection) -> str:\n",
    "        \"\"\"\n",
    "        To be used when the sample area overlaps more than one dataset feature.\n",
    "        \n",
    "        Return the value of 'property' for the largest overlap.\n",
    "        \"\"\"\n",
    "        # Add 'area' as a property to each feature. This is the area in square meters \n",
    "        # of the intersection of the ecoregion feature and the sample area.\n",
    "        overlaps = overlaps.map(\n",
    "            lambda feature: feature.set({'area': feature.geometry().area()}))\n",
    "\n",
    "        # Find the maximum area among all the overlaps\n",
    "        max_area = overlaps.aggregate_max('area')\n",
    "\n",
    "        # Return the overlap with the largest area\n",
    "        return ee.Feature(overlaps.filter(ee.Filter.gte('area', max_area)).first())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate your datasets\n",
    "Instantiate your chosen Earth Engine datasets in the list below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### BioClim data\n",
    "The [BioClim dataset](https://developers.google.com/earth-engine/datasets/catalog/WORLDCLIM_V1_BIO) has 19 bands representing different measures of temperature and precipitation to a resolution of 30 arc seconds (1 kilometer).\n",
    "\n",
    "Some of the bands have had their values multiplied by a factor of 10 or 100 in order to store the data in integer format. To get the actual values we need to divide each pixel in the image by that factor. We can do this with the [`ee.Image.divide`](https://developers.google.com/earth-engine/api_docs#ee.image.divide) function, which we apply to the `image` argument to our dataset constructors. In a similar way, any snippet which evaluates to an `ee.Image` or `ee.ImageCollection` object may be used as the input to the `RasterDataset` constructor. This way we can preprocess the dataset if desired, before extracting values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "bioclim = [\n",
    "    RasterDataset(\n",
    "        snippet=ee.Image('WORLDCLIM/V1/BIO').divide(ee.Image(10)),\n",
    "        band='bio01'\n",
    "    ),\n",
    "    RasterDataset(\n",
    "        snippet=ee.Image('WORLDCLIM/V1/BIO').divide(ee.Image(10)),\n",
    "        band='bio02'\n",
    "    ),\n",
    "    RasterDataset(\n",
    "        snippet=ee.Image('WORLDCLIM/V1/BIO'), \n",
    "        band='bio03'\n",
    "    ),\n",
    "    RasterDataset(\n",
    "        snippet=ee.Image('WORLDCLIM/V1/BIO').divide(ee.Image(100)), \n",
    "        band='bio04'\n",
    "    ),\n",
    "    RasterDataset(\n",
    "        snippet=ee.Image('WORLDCLIM/V1/BIO').divide(ee.Image(10)), \n",
    "        band='bio05'\n",
    "    ),\n",
    "    RasterDataset(\n",
    "        snippet=ee.Image('WORLDCLIM/V1/BIO').divide(ee.Image(10)), \n",
    "        band='bio06'\n",
    "    ),\n",
    "    RasterDataset(\n",
    "        snippet=ee.Image('WORLDCLIM/V1/BIO').divide(ee.Image(10)), \n",
    "        band='bio07'\n",
    "    ),\n",
    "    RasterDataset(\n",
    "        snippet=ee.Image('WORLDCLIM/V1/BIO').divide(ee.Image(10)), \n",
    "        band='bio08'\n",
    "    ),\n",
    "    RasterDataset(\n",
    "        snippet=ee.Image('WORLDCLIM/V1/BIO').divide(ee.Image(10)), \n",
    "        band='bio09'\n",
    "    ),\n",
    "    RasterDataset(\n",
    "        snippet=ee.Image('WORLDCLIM/V1/BIO').divide(ee.Image(10)), \n",
    "        band='bio10'\n",
    "    ),\n",
    "    RasterDataset(\n",
    "        snippet=ee.Image('WORLDCLIM/V1/BIO').divide(ee.Image(10)), \n",
    "        band='bio11'\n",
    "    ),\n",
    "    RasterDataset(\n",
    "        snippet=ee.Image('WORLDCLIM/V1/BIO'),\n",
    "        band='bio12'\n",
    "    ),\n",
    "    RasterDataset(\n",
    "        snippet=ee.Image('WORLDCLIM/V1/BIO'), \n",
    "        band='bio13'\n",
    "    ),\n",
    "    RasterDataset(\n",
    "        snippet=ee.Image('WORLDCLIM/V1/BIO'), \n",
    "        band='bio14'\n",
    "    ),\n",
    "    RasterDataset(\n",
    "        snippet=ee.Image('WORLDCLIM/V1/BIO'),\n",
    "        band='bio15'\n",
    "    ),\n",
    "    RasterDataset(\n",
    "        snippet=ee.Image('WORLDCLIM/V1/BIO'),\n",
    "        band='bio16'\n",
    "    ),\n",
    "    RasterDataset(\n",
    "        snippet=ee.Image('WORLDCLIM/V1/BIO'), \n",
    "        band='bio17'\n",
    "    ),\n",
    "    RasterDataset(\n",
    "        snippet=ee.Image('WORLDCLIM/V1/BIO'), \n",
    "        band='bio18'\n",
    "    ),\n",
    "    RasterDataset(\n",
    "        snippet=ee.Image('WORLDCLIM/V1/BIO'), \n",
    "        band='bio19'\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Level III Ecoregions\n",
    "The [EPA Level III Ecoregions of the Conterminous United States](https://developers.google.com/earth-engine/datasets/catalog/EPA_Ecoregions_2013_L3?hl=en) is our only dataset in vector format. We instantiate it as a `VectorDataset` and specify the property we want to extract from each feature, `us_l3name`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ecoregions = [\n",
    "    VectorDataset(\n",
    "        snippet=ee.FeatureCollection('EPA/Ecoregions/2013/L3'),\n",
    "        property='us_l3name',\n",
    "        map_params={'min': 0, 'max': 10}\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Soil properties\n",
    "Soil data is available at 250 meter resolution from [OpenLandMap datasets](https://developers.google.com/earth-engine/datasets/tags/openlandmap). We are selecting the values at surface level (band `b0`) but other bands correspond to depths of 10, 30, 60, 100, and 200 centimeters. Three of these datasets have been scaled up (shown in the 'Scale' column in the 'Bands' tab on the dataset pages) and so we divide them to get the true values.\n",
    "\n",
    "Since these datasets have band names which aren't self explanatory, for clarity we give them an alternate `name` which will be used in the output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "soil = [\n",
    "    RasterDataset(  # Soil taxonomy great groups, a classification number from 0 to 433\n",
    "        snippet=ee.Image('OpenLandMap/SOL/SOL_GRTGROUP_USDA-SOILTAX_C/v01'),\n",
    "        band='grtgroup',\n",
    "        categorical=True\n",
    "    ),\n",
    "    RasterDataset(\n",
    "        snippet=ee.Image('OpenLandMap/SOL/SOL_PH-H2O_USDA-4C1A2A_M/v02').divide(ee.Image(10)),\n",
    "        band='b0',\n",
    "        name='soil pH in H20'\n",
    "    ),\n",
    "    RasterDataset(\n",
    "        snippet=ee.Image('OpenLandMap/SOL/SOL_ORGANIC-CARBON_USDA-6A1C_M/v02').divide(ee.Image(5)),\n",
    "        band='b0',\n",
    "        name='soil organic carbon'\n",
    "    ),\n",
    "    RasterDataset(\n",
    "        snippet=ee.Image('OpenLandMap/SOL/SOL_SAND-WFRACTION_USDA-3A1A1A_M/v02'),\n",
    "        band='b0',\n",
    "        name='soil sand'\n",
    "    ),\n",
    "    RasterDataset(\n",
    "        snippet=ee.Image('OpenLandMap/SOL/SOL_CLAY-WFRACTION_USDA-3A1A1A_M/v02'),\n",
    "        band='b0',\n",
    "        name='soil clay'\n",
    "    ),\n",
    "    RasterDataset(\n",
    "        snippet=ee.Image('OpenLandMap/SOL/SOL_BULKDENS-FINEEARTH_USDA-4A1H_M/v02').divide(ee.Image(10)),\n",
    "        band='b0',\n",
    "        name='soil bulk density'\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Terrain\n",
    "Elevation data for the United States is available from the [USGS National Elevation dataset](https://developers.google.com/earth-engine/datasets/catalog/USGS_NED) at a resolution of 10 meters. Slope and aspect datasets are not available, but they are a direct function of elevation. Here we preprocess the elevation image using the [`ee.Terrain`](https://developers.google.com/earth-engine/api_docs#ee.terrain.aspect) functions to derive slope and aspect images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "terrain = [\n",
    "    RasterDataset(\n",
    "        snippet=ee.Image('USGS/NED'),\n",
    "        band='elevation'\n",
    "    ),\n",
    "    RasterDataset(\n",
    "        snippet=ee.Terrain.slope(ee.Image('USGS/NED')),\n",
    "        band='slope'\n",
    "    ),\n",
    "    RasterDataset(\n",
    "        snippet=ee.Terrain.aspect(ee.Image('USGS/NED')),\n",
    "        band='aspect'\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Landsat 8\n",
    "Datasets derived from composite Landsat 8 satellite imagery, taken about every 2 weeks at a 30 meter resolution, include normalized difference vegetation index (NDVI), enhanced vegetation index (EVI), normalized burn ratio thermal (NBRT), and greenest pixel.\n",
    "\n",
    "This is our first `ImageCollection` data. An `ImageCollection` represents a series of images over time. We will use the `ee.ImageCollection.filterDate` function to filter the series to our desired date range. The filtered collection will be mosaiced together to form a single image. \n",
    "\n",
    "* If you are interested in data from a specific point in time, you can set the date range accordingly, but be aware that data from a single day might not cover the entire area of interest. You will need to experiment with different ranges and find a minimal range that has complete coverage.\n",
    "\n",
    "* If the timestamp is not important to your data, you should still choose an appropriate date range, though it may be broader. If you do not specify a date range, overlapping images will be composited by their order in the collection, which could give you a mix of old and new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "landsat = [\n",
    "    RasterDataset(\n",
    "        snippet=ee.ImageCollection('LANDSAT/LC08/C01/T1_32DAY_NDVI').filterDate(\n",
    "            '2017-04-01', '2017-06-15'\n",
    "        ),\n",
    "        band='NDVI',\n",
    "        map_params={'min': 0, 'max': 1, 'palette': [\n",
    "    'FFFFFF', 'CE7E45', 'DF923D', 'F1B555', 'FCD163', '99B718', '74A901',\n",
    "    '66A000', '529400', '3E8601', '207401', '056201', '004C00', '023B01',\n",
    "    '012E01', '011D01', '011301'\n",
    "  ]}\n",
    "    ),\n",
    "    RasterDataset(\n",
    "        snippet=ee.ImageCollection('LANDSAT/LC08/C01/T1_8DAY_EVI').filterDate(\n",
    "            '2017-04-01', '2017-06-15'\n",
    "        ),\n",
    "        band='EVI'\n",
    "    ),\n",
    "    RasterDataset(\n",
    "        snippet=ee.ImageCollection('LANDSAT/LC08/C01/T1_8DAY_NBRT').filterDate(\n",
    "            '2017-04-01', '2017-06-15'\n",
    "        ),\n",
    "        band='NBRT'\n",
    "    ),\n",
    "    RasterDataset(\n",
    "        snippet=ee.Image('LANDSAT/LC8_L1T_ANNUAL_GREENEST_TOA/2017'),\n",
    "        band='greenness'\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Land cover\n",
    "The [USGS National Land Cover Database](https://developers.google.com/earth-engine/datasets/catalog/USGS_NLCD?hl=en) includes the landcover classification as well as continuous variables like percent impervious surface and percent tree cover at a 30 meter resolution.\n",
    "\n",
    "Here we see another kind of filter we can use to preprocess the data. Not all the bands we want are available in every image in the collection. We choose the most recent image, NLCD2016, by filtering on the image index.\n",
    "\n",
    "Note that landcover classification is a categorical variable and the others are continuous. We use `categorical=True` for landcover so that sample site values will be calculated by taking the mode rather than the median, which doesn't make sense for categorical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "landcover = [\n",
    "    RasterDataset(\n",
    "        snippet=ee.ImageCollection('USGS/NLCD').filterMetadata(\n",
    "            'system:index',\n",
    "            'equals',\n",
    "            'NLCD2011'\n",
    "        ),\n",
    "        band='landcover',\n",
    "        categorical=True,\n",
    "        map_params={'min': 0, 'max': 95}\n",
    "    ),\n",
    "    RasterDataset(\n",
    "        snippet=ee.ImageCollection('USGS/NLCD').filterMetadata(\n",
    "            'system:index',\n",
    "            'equals',\n",
    "            'NLCD2011'\n",
    "        ),\n",
    "        band='impervious'\n",
    "    ),\n",
    "    RasterDataset(\n",
    "        snippet=ee.ImageCollection('USGS/NLCD').filterMetadata(\n",
    "            'system:index',\n",
    "            'equals',\n",
    "            'NLCD2011'\n",
    "        ),\n",
    "        band='percent_tree_cover'\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentinel 2\n",
    "The Sentinel 2 satellites https://developers.google.com/earth-engine/datasets/catalog/COPERNICUS_S2 continuously take multi-spectral imagery of the Earth, covering a given location once every 5 days on average since 2015. Resolution is 10, 20, or 60 meters depending on the band.\n",
    "\n",
    "This data needs a few preprocessing steps. Because this dataset is huge with tens of thousands of images, using all of them would be very slow. We filter to a date range and filter out images with more than 20% cloudy pixels. We define a method that filters the set to only include images covering California. We also define a cloud masking function, which makes pixels transparent if the QA60 band indicates they have cloud or cirrus cover. And we reduce the `ImageCollection` to a single `Image` by using the `median` method, which sets each pixel to the median value from all images covering that point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_clouds(image: ee.Image) -> ee.Image:\n",
    "    '''Return the image with clouds masked'''\n",
    "    \n",
    "    qa = image.select('QA60')\n",
    "\n",
    "    # Bits 10 and 11 are clouds and cirrus, respectively.\n",
    "    cloudBitMask = int(2 ** 10)\n",
    "    cirrusBitMask = int(2 ** 11)\n",
    "\n",
    "    # Both flags should be set to zero, indicating clear conditions.\n",
    "    mask = qa.bitwiseAnd(cloudBitMask).eq(0).And(qa.bitwiseAnd(cirrusBitMask).eq(0))\n",
    "    image = image.updateMask(mask)\n",
    "    \n",
    "    return image\n",
    "\n",
    "def filter_california(collection: ee.ImageCollection) -> ee.ImageCollection:\n",
    "    '''Filter the collection to just those images overlapping California'''\n",
    "    # Define a rectangular area just big enough to contain all of California\n",
    "    california = ee.Geometry.Polygon([\n",
    "        ee.Geometry.Point(-125, 32.5),\n",
    "        ee.Geometry.Point(-125, 42),\n",
    "        ee.Geometry.Point(-114, 42),\n",
    "        ee.Geometry.Point(-114, 32.5)\n",
    "    ])\n",
    "    # Return a collection of just those images that are within California\n",
    "    return collection.filterBounds(california)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we preprocess the collection. We filter the collection to include just those images that are in California and within a date range (adjust this as appropriate for your data). We apply the cloud masking function to each image, then divide each image by 10000 to correct the scale. This preprocessed collection is used as the input to the `RasterDataset` constructors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sentinel_preprocessed = filter_california(\n",
    "                            ee.ImageCollection(\"COPERNICUS/S2\")\n",
    "                        ).filterDate(\n",
    "                            '2017-01-01', \n",
    "                            '2018-07-01'\n",
    "                        ).filter(\n",
    "                            ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 20)\n",
    "                        ).map(\n",
    "                            lambda img: mask_clouds(img).divide(\n",
    "                                ee.Image(10000)\n",
    "                            )\n",
    "                        ).median()\n",
    "\n",
    "sentinel = [\n",
    "    RasterDataset(\n",
    "        snippet=sentinel_preprocessed,\n",
    "        band='B1',\n",
    "    ),\n",
    "    RasterDataset(\n",
    "        snippet=sentinel_preprocessed,\n",
    "        band='B2',\n",
    "        map_params={'min': 0, 'max': 1}\n",
    "    ),\n",
    "    RasterDataset(\n",
    "        snippet=sentinel_preprocessed,\n",
    "        band='B3',\n",
    "        map_params={'min': 0, 'max': 1}\n",
    "    ),\n",
    "    RasterDataset(\n",
    "        snippet=sentinel_preprocessed,\n",
    "        band='B4',\n",
    "        map_params={'min': 0, 'max': 1}\n",
    "    ),\n",
    "    RasterDataset(\n",
    "        snippet=sentinel_preprocessed,\n",
    "        band='B5'\n",
    "    ),\n",
    "    RasterDataset(\n",
    "        snippet=sentinel_preprocessed,\n",
    "        band='B6'\n",
    "    ),\n",
    "    RasterDataset(\n",
    "        snippet=sentinel_preprocessed,\n",
    "        band='B7'\n",
    "    ),\n",
    "    RasterDataset(\n",
    "        snippet=sentinel_preprocessed,\n",
    "        band='B8'\n",
    "    ),\n",
    "    RasterDataset(\n",
    "        snippet=sentinel_preprocessed,\n",
    "        band='B8A'\n",
    "    ),\n",
    "    RasterDataset(\n",
    "        snippet=sentinel_preprocessed,\n",
    "        band='B9'\n",
    "    ),\n",
    "    RasterDataset(\n",
    "        snippet=sentinel_preprocessed,\n",
    "        band='B10'\n",
    "    ),\n",
    "    RasterDataset(\n",
    "        snippet=sentinel_preprocessed,\n",
    "        band='B11'\n",
    "    ),\n",
    "    RasterDataset(\n",
    "        snippet=sentinel_preprocessed,\n",
    "        band='B12'\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate the lists of datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the list of datasets from which to retrieve data\n",
    "datasets = bioclim + ecoregions + soil + terrain + landsat + landcover + sentinel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Here is an extra function for reprojecting an Image to a different scale. \n",
    "# Might be useful for something, not sure what effect this has exactly\n",
    "\n",
    "def reproject(image: ee.Image, scale: int) -> ee.Image:\n",
    "    '''\n",
    "    Resample and reproject an image to a different resolution.\n",
    "    \n",
    "    param image: Image to reproject\n",
    "    param scale: Desired pixel width in meters\n",
    "    '''\n",
    "    return image.resample('bilinear').reproject(  # Use bilinear interpolation method\n",
    "        crs=image.projection().crs(),  # Keep the same map projection\n",
    "        scale=scale  # Change the scale\n",
    "    )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Map the data\n",
    "Next we define a mapping class and some methods to help visualize the data. This will help with understanding what we're doing, and also make it easy to visually verify that the results make sense. The JavaScript version of the Earth Engine API provides a Map class that makes it easy to do this, but the Python API doesn't have that feature. I'm implementing it using Folium, a Python library for creating Leaflet Javascript maps, as recommended [here](https://developers.google.com/earth-engine/python_install-colab.html#interactive_map)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These two methods are going to be added as custom folium map methods. \n",
    "# This will make it easy to display vector and raster Earth Engine objects to a map.\n",
    "def add_raster_layer(self, ee_image_object, vis_params, name):\n",
    "    \"\"\"\n",
    "    Display an EE image (raster) on a folium map\n",
    "    \n",
    "    param ee_image_object: ee.Image to add to the map\n",
    "    param vis_params: map visualization parameters e.g. min, max, palette\n",
    "    param name: name to give the layer in the layer control panel display\n",
    "    \"\"\"\n",
    "    map_id_dict = ee.Image(ee_image_object).getMapId(vis_params)\n",
    "    folium.raster_layers.TileLayer(\n",
    "        tiles = map_id_dict['tile_fetcher'].url_format,\n",
    "        attr = \"Map Data © Google Earth Engine\",\n",
    "        name = name,\n",
    "        overlay = True,\n",
    "        control = True\n",
    "    ).add_to(self)\n",
    "\n",
    "def add_vector_layer(self, coords, name):\n",
    "    \"\"\"\n",
    "    Display an EE geometry (vector) on a folium map\n",
    "    \n",
    "    param ee_image_object: ee.Image to add to the map\n",
    "    param vis_params: map visualization parameters e.g. min, max, palette\n",
    "    param name: name to give the layer in the layer control panel display\n",
    "    \"\"\"\n",
    "    # Reverse the order of the coordinates from (lng, lat) to (lat, lng)\n",
    "    coords = np.array([np.flip(i) for i in coords])\n",
    "    \n",
    "    # Add the coordinates as a polygon layer in the map\n",
    "    folium.vector_layers.Polygon(\n",
    "        locations=coords,\n",
    "        name=name,\n",
    "        color='red',\n",
    "        overlay=True,\n",
    "        control=True,\n",
    "        tooltip=name\n",
    "    ).add_to(self)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we define the Map class, which makes use of the above methods to draw multiple datasets onto a folium map and display it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Map:\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize a custom folium map\"\"\"\n",
    "        # Add EE drawing methods to folium.\n",
    "        folium.Map.add_raster_layer = add_raster_layer\n",
    "        folium.Map.add_vector_layer = add_vector_layer\n",
    "        \n",
    "        # Centers the map on California. Adjust the center coordinates and zoom level for your data\n",
    "        self.map = folium.Map(location=[35, -119], zoom_start=4, height=500)\n",
    "        \n",
    "    def add_polygon(self, coords: np.ndarray, name: str):\n",
    "        \"\"\"\n",
    "        Add a polygon to the map\n",
    "        \n",
    "        param coords: array of (lng, lat) coordinate pairs outlining the polygon\n",
    "        param name: name to give the polygon to display as a tooltip\n",
    "        \"\"\"\n",
    "        self.map.add_vector_layer(coords, name)\n",
    "\n",
    "    def add(self, dataset):\n",
    "        \"\"\"Add a dataset as a layer to an interactive map using folium\"\"\"\n",
    "\n",
    "        # If the dataset is in vector format, we want to convert it to raster in order to \n",
    "        # display on the map more easily,\n",
    "        if isinstance(dataset, VectorDataset):\n",
    "            map_property = dataset.property\n",
    "            \n",
    "            # Non-numeric values can't be converted into raster format\n",
    "            # We will have to arbitrarily assign numeric values to represent them\n",
    "            if not isinstance(dataset.data.first().get(dataset.property), ee.Number):\n",
    "                # Get an array of all existing values of the property\n",
    "                values = ee.List(dataset.data.aggregate_array(dataset.property))\n",
    "                # Use the index of each property in the array as an arbitrary numeric value\n",
    "                # e.g. if your values were ['forest', 'desert', 'water'],\n",
    "                # the new band would have values [0, 1, 2] respectively.\n",
    "                dataset.data = dataset.data.map(\n",
    "                    lambda feature: feature.set(\n",
    "                        'as_number', values.indexOf(feature.get(dataset.property)))\n",
    "                )\n",
    "                # Do mapping based on the new numeric property\n",
    "                map_property = 'as_number'\n",
    "            \n",
    "            # Convert to a raster image, turning values of the given property into pixel values\n",
    "            image = dataset.data.reduceToImage(\n",
    "                properties=[map_property], reducer=ee.Reducer.first())\n",
    "            \n",
    "        # If it's in raster format, we can use it as-is\n",
    "        else:\n",
    "            image = dataset.data\n",
    "        \n",
    "        self.map.add_raster_layer(\n",
    "            image.updateMask(image.gt(0)), \n",
    "            dataset.map_params, \n",
    "            dataset.name)\n",
    "        \n",
    "    def get_coords(fc: ee.FeatureCollection) -> np.array:\n",
    "        \"\"\"\n",
    "        Return a list of coordinate lists representing the geometries \n",
    "        of the features in the FeatureCollection.\n",
    "        \"\"\"\n",
    "        coords = np.array(fc.iterate(\n",
    "            lambda item, l: ee.List(l).add(item.geometry().coordinates()), \n",
    "            ee.List([])).getInfo())\n",
    "        return coords\n",
    "    \n",
    "    def get_names(fc: ee.FeatureCollection) -> np.array:\n",
    "        \"\"\"\n",
    "        Return a list of names extracted from the 'name' property of each \n",
    "        feature in the FeatureCollection.\n",
    "        \"\"\"\n",
    "        names = np.array(fc.iterate(\n",
    "            lambda item, l: ee.List(l).add(item.get('name')), \n",
    "            ee.List([])).getInfo())\n",
    "        return names\n",
    "\n",
    "    def display(self):\n",
    "        \"\"\"Display the map\"\"\"\n",
    "        self.map.add_child(folium.LayerControl())  # Add a layer control panel to the map\n",
    "        display(self.map)   # Display the map\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bio01\n",
      "bio02\n",
      "bio03\n",
      "bio04\n",
      "bio05\n",
      "bio06\n",
      "bio07\n",
      "bio08\n",
      "bio09\n",
      "bio10\n",
      "bio11\n",
      "bio12\n",
      "bio13\n",
      "bio14\n",
      "bio15\n",
      "bio16\n",
      "bio17\n",
      "bio18\n",
      "bio19\n",
      "us_l3name\n",
      "grtgroup\n",
      "soil pH in H20\n",
      "soil organic carbon\n",
      "soil sand\n",
      "soil clay\n",
      "soil bulk density\n",
      "elevation\n",
      "slope\n",
      "aspect\n",
      "NDVI\n",
      "EVI\n",
      "NBRT\n",
      "greenness\n",
      "landcover\n",
      "impervious\n",
      "percent_tree_cover\n",
      "B1\n",
      "B2\n",
      "B3\n",
      "B4\n",
      "B5\n",
      "B6\n",
      "B7\n",
      "B8\n",
      "B8A\n",
      "B9\n",
      "B10\n",
      "B11\n",
      "B12\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-beeccb3a1234>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0msample_areas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_areas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_sample_area_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# Add the dataset as a layer to the map\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mmap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Display the map\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-394f3f28807b>\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         self.map.add_raster_layer(\n\u001b[0m\u001b[1;32m     51\u001b[0m             \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdateMask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-a635afaa2ddb>\u001b[0m in \u001b[0;36madd_raster_layer\u001b[0;34m(self, ee_image_object, vis_params, name)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mparam\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mname\u001b[0m \u001b[0mto\u001b[0m \u001b[0mgive\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0mcontrol\u001b[0m \u001b[0mpanel\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \"\"\"\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mmap_id_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mee\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mee_image_object\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetMapId\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvis_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     folium.raster_layers.TileLayer(\n\u001b[1;32m     13\u001b[0m         \u001b[0mtiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap_id_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tile_fetcher'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ee/lib/python3.8/site-packages/ee/image.py\u001b[0m in \u001b[0;36mgetMapId\u001b[0;34m(self, vis_params)\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0mvis_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_visualization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvis_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0mrequest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvis_image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetMapId\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m     \u001b[0mresponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ee/lib/python3.8/site-packages/ee/data.py\u001b[0m in \u001b[0;36mgetMapId\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m    586\u001b[0m     \u001b[0;31m# Make it return only the name field, as otherwise it echoes the entire\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m     \u001b[0;31m# request, which might be large.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m     result = _execute_cloud_call(_cloud_api_resource.projects().maps().create(\n\u001b[0m\u001b[1;32m    589\u001b[0m         \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_get_projects_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0mfields\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ee/lib/python3.8/site-packages/ee/data.py\u001b[0m in \u001b[0;36m_execute_cloud_call\u001b[0;34m(call, num_retries)\u001b[0m\n\u001b[1;32m    336\u001b[0m   \"\"\"\n\u001b[1;32m    337\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 338\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_retries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_retries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    339\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mapiclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHttpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0m_translate_cloud_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ee/lib/python3.8/site-packages/googleapiclient/_helpers.py\u001b[0m in \u001b[0;36mpositional_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    132\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mpositional_parameters_enforcement\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mPOSITIONAL_WARNING\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpositional_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ee/lib/python3.8/site-packages/googleapiclient/http.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, http, num_retries)\u001b[0m\n\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m         \u001b[0;31m# Handle retries for server-side errors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 883\u001b[0;31m         resp, content = _retry_request(\n\u001b[0m\u001b[1;32m    884\u001b[0m             \u001b[0mhttp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    885\u001b[0m             \u001b[0mnum_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ee/lib/python3.8/site-packages/googleapiclient/http.py\u001b[0m in \u001b[0;36m_retry_request\u001b[0;34m(http, num_retries, req_type, sleep, rand, uri, method, *args, **kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0mexception\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m             \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhttp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m         \u001b[0;31m# Retry on SSL errors and socket timeout errors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0m_ssl_SSLError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mssl_error\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ee/lib/python3.8/site-packages/google_auth_httplib2.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, uri, method, body, headers, **kwargs)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0;31m# Make the request.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m         response, content = self.http.request(\n\u001b[0m\u001b[1;32m    198\u001b[0m             uri, method, body=body, headers=request_headers, **kwargs)\n\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ee/lib/python3.8/site-packages/httplib2/__init__.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, uri, method, body, headers, redirections, connection_type)\u001b[0m\n\u001b[1;32m   1980\u001b[0m                     \u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mb\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1981\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1982\u001b[0;31m                     (response, content) = self._request(\n\u001b[0m\u001b[1;32m   1983\u001b[0m                         \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1984\u001b[0m                         \u001b[0mauthority\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ee/lib/python3.8/site-packages/httplib2/__init__.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, conn, host, absolute_uri, request_uri, method, body, headers, redirections, cachekey)\u001b[0m\n\u001b[1;32m   1648\u001b[0m             \u001b[0mauth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest_uri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1650\u001b[0;31m         (response, content) = self._conn_request(\n\u001b[0m\u001b[1;32m   1651\u001b[0m             \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest_uri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1652\u001b[0m         )\n",
      "\u001b[0;32m~/miniconda3/envs/ee/lib/python3.8/site-packages/httplib2/__init__.py\u001b[0m in \u001b[0;36m_conn_request\u001b[0;34m(self, conn, request_uri, method, body, headers)\u001b[0m\n\u001b[1;32m   1587\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1588\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1589\u001b[0;31m                 \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1590\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhttp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBadStatusLine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhttp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResponseNotReady\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1591\u001b[0m                 \u001b[0;31m# If we get a BadStatusLine on the first try then that means\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ee/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ee/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    301\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 303\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    304\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ee/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ee/lib/python3.8/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 669\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    670\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ee/lib/python3.8/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1239\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1240\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1241\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1242\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1243\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ee/lib/python3.8/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1097\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1099\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1100\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Define a map that will display all the data together, and add each sample area geometry to it\n",
    "map = Map()\n",
    "for polygon, name in zip(Map.get_coords(sample_areas), Map.get_names(sample_areas)):\n",
    "    map.add_polygon(polygon, name=name)\n",
    "\n",
    "# For each dataset,\n",
    "for dataset in datasets:\n",
    "    print(dataset.name)\n",
    "    # Add a property to each sample area storing the value calculated from the dataset\n",
    "    sample_areas = sample_areas.map(lambda feature: dataset.get_sample_area_data(feature))\n",
    "    # Add the dataset as a layer to the map\n",
    "    map.add(dataset)\n",
    "    \n",
    "map.display()  # Display the map\n",
    "\n",
    "# Get the name of each dataset, which will be the column headers\n",
    "dataset_names = [dataset.name for dataset in datasets]\n",
    "\n",
    "# Export the sample area data to your Google Drive as a CSV\n",
    "# Note: It may take a few minutes to show up.\n",
    "task = ee.batch.Export.table.toDrive(\n",
    "    collection=sample_areas, \n",
    "    description='eedata',  # The file will show up in your Drive with this name\n",
    "    selectors=['name', 'latitude', 'longitude'] + dataset_names  # Don't output geometry property\n",
    ")\n",
    "task.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
